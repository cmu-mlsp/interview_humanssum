{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03152c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c707bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read Data \n",
    "output_df = pd.read_csv('../data/release_data_summaries_expert.tsv',sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62785456",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ca6699",
   "metadata": {},
   "source": [
    "# Transcript Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42241b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summary1_lengths = output_df[\"Text_Summary1\"].apply(lambda x: len(x.split(\" \"))).tolist()\n",
    "text_summary2_lengths = output_df[\"Text_Summary2\"].apply(lambda x: len(x.split(\" \"))).tolist()\n",
    "audio_summary1_lengths = output_df[\"Audio_Summary1\"].apply(lambda x: len(x.split(\" \"))).tolist()\n",
    "audio_summary2_lengths = output_df[\"Audio_Summary2\"].apply(lambda x: len(x.split(\" \"))).tolist()\n",
    "asr_summary1_lengths = output_df[\"Whisper_Transcript_Summary1\"].apply(lambda x: len(x.split(\" \"))).tolist()\n",
    "asr_summary2_lengths = output_df[\"Whisper_Transcript_Summary2\"].apply(lambda x: len(x.split(\" \"))).tolist()\n",
    "transcript_lengths = output_df[\"transcript\"].apply(lambda x: len(x.split(\" \"))).tolist()\n",
    "\n",
    "mean_text_summary = (text_summary1_lengths + text_summary2_lengths)\n",
    "mean_audio_summary = (audio_summary1_lengths+audio_summary2_lengths)\n",
    "mean_asr_summary = (asr_summary1_lengths+asr_summary2_lengths)\n",
    "\n",
    "\n",
    "audio_compression_ratio = [0.5*(audio_summary1_lengths[i]+audio_summary2_lengths[i])/transcript_lengths[i] for i in range(len(audio_summary1_lengths))]\n",
    "text_compression_ratio = [0.5*(text_summary1_lengths[i]+text_summary2_lengths[i])/transcript_lengths[i] for i in range(len(text_summary1_lengths))]\n",
    "asr_compression_ratio = [0.5*(asr_summary1_lengths[i]+asr_summary2_lengths[i])/transcript_lengths[i] for i in range(len(asr_summary1_lengths))]\n",
    "\n",
    "print(f\"SLENGTH {np.mean(mean_text_summary)} {np.std(mean_text_summary)} {np.mean(mean_audio_summary)} {np.std(mean_asr_summary)} {np.mean(mean_asr_summary)} {np.std(mean_asr_summary)} {get_pvalues(mean_text_summary,mean_audio_summary)} {get_pvalues(mean_text_summary,mean_asr_summary)} {get_pvalues(mean_asr_summary,mean_audio_summary)} \")\n",
    "\n",
    "print(f\"CRATIO {np.mean(audio_compression_ratio)} {np.std(audio_compression_ratio)} {np.mean(text_compression_ratio)} {np.std(text_compression_ratio)} {get_pvalues(audio_compression_ratio,text_compression_ratio)} {get_pvalues(asr_compression_ratio,text_compression_ratio)} {get_pvalues(asr_compression_ratio,audio_compression_ratio)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    " \n",
    "# Load spaCy English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "\n",
    "def get_entities(text):\n",
    "    return [ent.text for ent in nlp(text).ents]\n",
    "\n",
    "output_df[\"Text_Summary1_Entities\"] = output_df[\"Text_Summary1\"].apply(lambda x: get_entities(x))\n",
    "output_df[\"Text_Summary2_Entities\"] = output_df[\"Text_Summary2\"].apply(lambda x: get_entities(x))\n",
    "output_df[\"Audio_Summary1_Entities\"] = output_df[\"Audio_Summary1\"].apply(lambda x: get_entities(x))\n",
    "output_df[\"Audio_Summary2_Entities\"] = output_df[\"Audio_Summary2\"].apply(lambda x: get_entities(x))\n",
    "output_df[\"Whisper_Transcript_Summary1_Entities\"] = output_df[\"Whisper_Transcript_Summary1\"].apply(lambda x: get_entities(x))\n",
    "output_df[\"Whisper_Transcript_Summary2_Entities\"] = output_df[\"Whisper_Transcript_Summary2\"].apply(lambda x: get_entities(x))\n",
    "output_df[\"Transcript_Entities\"] = output_df[\"transcript\"].apply(lambda x: get_entities(x))\n",
    "\n",
    "def process_entity_f1(ref_list,hyp_list):\n",
    "    ref_list = [x.lower() for x in ref_list]\n",
    "    hyp_list = [x.lower() for x in hyp_list]\n",
    "    ref_set = set(ref_list)\n",
    "    hyp_set = set(hyp_list)\n",
    "    tp = len(ref_set.intersection(hyp_set))\n",
    "    precision = tp/len(hyp_set) if len(hyp_set) > 0 else 0\n",
    "    recall = tp/len(ref_set) if len(ref_set) > 0 else 0\n",
    "    f1 = 2*precision*recall/(precision+recall) if precision+recall > 0 else 0\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summary1_entity_f1 = output_df.apply(lambda x: process_entity_f1(x[\"Transcript_Entities\"],x[\"Text_Summary1_Entities\"]),axis=1).tolist()\n",
    "text_summary2_entity_f1 = output_df.apply(lambda x: process_entity_f1(x[\"Transcript_Entities\"],x[\"Text_Summary2_Entities\"]),axis=1).tolist()\n",
    "audio_summary1_entity_f1 = output_df.apply(lambda x: process_entity_f1(x[\"Transcript_Entities\"],x[\"Audio_Summary1_Entities\"]),axis=1).tolist()\n",
    "audio_summary2_entity_f1 = output_df.apply(lambda x: process_entity_f1(x[\"Transcript_Entities\"],x[\"Audio_Summary2_Entities\"]),axis=1).tolist()\n",
    "asr_summary1_entity_f1 = output_df.apply(lambda x: process_entity_f1(x[\"Transcript_Entities\"],x[\"Whisper_Transcript_Summary1_Entities\"]),axis=1).tolist()\n",
    "asr_summary2_entity_f1 = output_df.apply(lambda x: process_entity_f1(x[\"Transcript_Entities\"],x[\"Whisper_Transcript_Summary2_Entities\"]),axis=1).tolist()\n",
    "\n",
    "\n",
    "text_ents = text_summary1_entity_f1 + text_summary2_entity_f1\n",
    "audio_ents = audio_summary1_entity_f1 + audio_summary2_entity_f1\n",
    "asr_ents = asr_summary1_entity_f1 + asr_summary2_entity_f1\n",
    "\n",
    "print(f\"ENTITIES {np.mean(text_ents)} {np.std(text_ents)} {np.mean(audio_ents)} {np.std(audio_ents)} {np.mean(asr_ents)} {np.std(asr_ents)} {get_pvalues(text_ents,audio_ents)} {get_pvalues(text_ents,asr_ents)} {get_pvalues(asr_ents,audio_ents)}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d8c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate \n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "def compute_rouge(hyp,ref):\n",
    "    results = rouge.compute(predictions=[hyp],references=[ref])\n",
    "    return results[\"rougeL\"]\n",
    "\n",
    "text_summary1_transcript_rouge = output_df.apply(lambda x: compute_rouge(x[\"Text_Summary1\"],x[\"transcript\"]),axis=1).tolist()\n",
    "text_summary2_transcript_rouge = output_df.apply(lambda x: compute_rouge(x[\"Text_Summary2\"],x[\"transcript\"]),axis=1).tolist()\n",
    "audio_summary1_transcript_rouge = output_df.apply(lambda x: compute_rouge(x[\"Audio_Summary1\"],x[\"transcript\"]),axis=1).tolist()\n",
    "audio_summary2_transcript_rouge = output_df.apply(lambda x: compute_rouge(x[\"Audio_Summary2\"],x[\"transcript\"]),axis=1).tolist()\n",
    "asr_summary1_transcript_rouge = output_df.apply(lambda x: compute_rouge(x[\"Whisper_Transcript_Summary1\"],x[\"transcript\"]),axis=1).tolist()\n",
    "asr_summary2_transcript_rouge = output_df.apply(lambda x: compute_rouge(x[\"Whisper_Transcript_Summary2\"],x[\"transcript\"]),axis=1).tolist()\n",
    "\n",
    "text_rouge = text_summary1_transcript_rouge + text_summary2_transcript_rouge\n",
    "audio_rouge = audio_summary1_transcript_rouge + audio_summary2_transcript_rouge\n",
    "asr_rouge = asr_summary1_transcript_rouge + asr_summary2_transcript_rouge\n",
    "\n",
    "print(f\"ROUGE {np.mean(text_rouge)} {np.std(text_rouge)} {np.mean(audio_rouge)} {np.std(audio_rouge)} {np.mean(asr_rouge)} {np.std(asr_rouge)} {get_pvalues(text_rouge,audio_rouge)} {get_pvalues(text_rouge,asr_rouge)} {get_pvalues(asr_rouge,audio_rouge)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate \n",
    "\n",
    "\n",
    "meteor = evaluate.load('meteor')\n",
    "\n",
    "def compute_meteor(hyp,ref):\n",
    "    results = meteor.compute(predictions=[hyp.lower()],references=[ref.lower()])\n",
    "    return results[\"meteor\"]\n",
    "\n",
    "text_summary1_transcript_meteor = output_df.apply(lambda x: compute_meteor(x[\"Text_Summary1\"],x[\"transcript\"]),axis=1).tolist()\n",
    "text_summary2_transcript_meteor = output_df.apply(lambda x: compute_meteor(x[\"Text_Summary2\"],x[\"transcript\"]),axis=1).tolist()\n",
    "audio_summary1_transcript_meteor = output_df.apply(lambda x: compute_meteor(x[\"Audio_Summary1\"],x[\"transcript\"]),axis=1).tolist()\n",
    "audio_summary2_transcript_meteor = output_df.apply(lambda x: compute_meteor(x[\"Audio_Summary2\"],x[\"transcript\"]),axis=1).tolist()\n",
    "asr_summary1_transcript_meteor = output_df.apply(lambda x: compute_meteor(x[\"Whisper_Transcript_Summary1\"],x[\"transcript\"]),axis=1).tolist()\n",
    "asr_summary2_transcript_meteor = output_df.apply(lambda x: compute_meteor(x[\"Whisper_Transcript_Summary2\"],x[\"transcript\"]),axis=1).tolist()\n",
    "\n",
    "text_meteor = text_summary1_transcript_meteor + text_summary2_transcript_meteor\n",
    "audio_meteor = audio_summary1_transcript_meteor +   audio_summary2_transcript_meteor\n",
    "asr_meteor = asr_summary1_transcript_meteor + asr_summary2_transcript_meteor\n",
    "\n",
    "print(f\"METEOR {np.mean(text_meteor)} {np.std(text_meteor)} {np.mean(audio_meteor)} {np.std(audio_meteor)} {np.mean(asr_meteor)} {np.std(asr_meteor)} {get_pvalues(text_meteor,audio_meteor)} {get_pvalues(text_meteor,asr_meteor)} {get_pvalues(asr_meteor,audio_meteor)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5156d959",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "def compute_bertscore(hyp,ref):\n",
    "    results = bertscore.compute(predictions=[hyp],references=[ref],lang=\"en\")\n",
    "    return results[\"f1\"][0]\n",
    "\n",
    "text_summary1_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Text_Summary1\"],x[\"transcript\"]),axis=1).tolist()\n",
    "text_summary2_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Text_Summary2\"],x[\"transcript\"]),axis=1).tolist()\n",
    "audio_summary1_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Audio_Summary1\"],x[\"transcript\"]),axis=1).tolist()\n",
    "audio_summary2_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Audio_Summary2\"],x[\"transcript\"]),axis=1).tolist()\n",
    "asr_summary1_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Whisper_Transcript_Summary1\"],x[\"transcript\"]),axis=1).tolist()\n",
    "asr_summary2_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Whisper_Transcript_Summary2\"],x[\"transcript\"]),axis=1).tolist()\n",
    "\n",
    "\n",
    "text_bertscore = text_summary1_transcript_bertscore + text_summary2_transcript_bertscore\n",
    "audio_bertscore = audio_summary1_transcript_bertscore + audio_summary2_transcript_bertscore\n",
    "asr_bertscore = asr_summary1_transcript_bertscore + asr_summary2_transcript_bertscore\n",
    "\n",
    "print(f\"BERTSCORE {np.mean(text_bertscore)} {np.std(text_bertscore)} {np.mean(audio_bertscore)} {np.std(audio_bertscore)} {np.mean(asr_bertscore)} {np.std(asr_bertscore)} {get_pvalues(text_bertscore,audio_bertscore)} {get_pvalues(text_bertscore,asr_bertscore)} {get_pvalues(asr_bertscore,audio_bertscore)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd11d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summary1_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Text_Summary1\"],x[\"Text_Summary2\"]),axis=1).tolist()\n",
    "text_summary2_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Text_Summary2\"],x[\"Text_Summary1\"]),axis=1).tolist()\n",
    "audio_summary1_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Audio_Summary1\"],x[\"Audio_Summary2\"]),axis=1).tolist()\n",
    "audio_summary2_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Audio_Summary2\"],x[\"Audio_Summary1\"]),axis=1).tolist()\n",
    "asr_summary1_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Whisper_Transcript_Summary1\"],x[\"Whisper_Transcript_Summary2\"]),axis=1).tolist()\n",
    "asr_summary2_transcript_bertscore = output_df.apply(lambda x: compute_bertscore(x[\"Whisper_Transcript_Summary2\"],x[\"Whisper_Transcript_Summary1\"]),axis=1).tolist()\n",
    "\n",
    "print(f\"BSINT {np.mean(text_summary1_transcript_bertscore+text_summary2_transcript_bertscore)} {np.std(text_summary1_transcript_bertscore+text_summary2_transcript_bertscore)} {np.mean(audio_summary1_transcript_bertscore+audio_summary2_transcript_bertscore)} {np.std(audio_summary1_transcript_bertscore+audio_summary2_transcript_bertscore)} {np.mean(asr_summary1_transcript_bertscore+asr_summary2_transcript_bertscore)} {np.std(asr_summary1_transcript_bertscore+asr_summary2_transcript_bertscore)} {get_pvalues(text_summary1_transcript_bertscore+text_summary2_transcript_bertscore,audio_summary1_transcript_bertscore+audio_summary2_transcript_bertscore)} {get_pvalues(text_summary1_transcript_bertscore+text_summary2_transcript_bertscore,asr_summary1_transcript_bertscore+asr_summary2_transcript_bertscore)} {get_pvalues(asr_summary1_transcript_bertscore+asr_summary2_transcript_bertscore,audio_summary1_transcript_bertscore+audio_summary2_transcript_bertscore)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a6742",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summary1 = list(output_df[\"Text_Summary1\"])\n",
    "text_summary2 = list(output_df[\"Text_Summary2\"])\n",
    "audio_summary1 = list(output_df[\"Audio_Summary1\"])\n",
    "audio_summary2 = list(output_df[\"Audio_Summary2\"])\n",
    "asr_summary1 = list(output_df[\"Whisper_Transcript_Summary1\"])\n",
    "asr_summary2 = list(output_df[\"Whisper_Transcript_Summary2\"])\n",
    "\n",
    "src = list(output_df[\"transcript\"])\n",
    "ref = list(output_df[\"ref\"])\n",
    "\n",
    "\n",
    "print(len(text_summary1),len(text_summary2),len(audio_summary1),len(audio_summary2),len(src),len(ref),len(asr_summary1),len(asr_summary2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed9f7f5",
   "metadata": {},
   "source": [
    "# UniEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c382ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd UniEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d4d5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import convert_to_json\n",
    "from metric.evaluator import get_evaluator\n",
    "\n",
    "task = 'summarization'\n",
    "\n",
    "evaluator = get_evaluator(task)\n",
    "\n",
    "\n",
    "def compute_unieval_scores(hyp_list,ref_list,src_list):\n",
    "    data = convert_to_json(src_list=src_list, ref_list=ref_list,output_list=hyp_list)\n",
    "    eval_scores = evaluator.evaluate(data, dims=['coherence', 'consistency', 'fluency'], \n",
    "                                 overall=False, print_result=False)\n",
    "    return [x[\"coherence\"] for x in eval_scores],[x[\"consistency\"] for x in eval_scores],[x[\"fluency\"] for x in eval_scores]\n",
    "\n",
    "\n",
    "\n",
    "ts1_coh,ts1_con,ts1_flu = compute_unieval_scores(text_summary1,ref,src)\n",
    "ts2_coh,ts2_con,ts2_flu = compute_unieval_scores(text_summary2,ref,src)\n",
    "ss1_coh,ss1_con,ss1_flu = compute_unieval_scores(audio_summary1,ref,src)\n",
    "ss2_coh,ss2_con,ss2_flu = compute_unieval_scores(audio_summary2,ref,src)\n",
    "as1_coh,as1_con,as1_flu = compute_unieval_scores(asr_summary1,ref,src)\n",
    "as2_coh,as2_con,as2_flu = compute_unieval_scores(asr_summary2,ref,src)\n",
    "\n",
    "ts_coh = ts1_coh + ts2_coh\n",
    "ss_coh = ss1_coh + ss2_coh\n",
    "as_coh = as1_coh + as2_coh\n",
    "ts_con = ts1_con + ts2_con\n",
    "ss_con = ss1_con + ss2_con\n",
    "as_con = as1_con + as2_con\n",
    "ts_flu = ts1_flu + ts2_flu\n",
    "ss_flu = ss1_flu + ss2_flu\n",
    "as_flu = as1_flu + as2_flu\n",
    "\n",
    "print(f\"UEVALCOH {np.mean(ts_coh)} {np.std(ts_coh)} {np.mean(ss_coh)} {np.std(ss_coh)} {np.mean(as_coh)} {np.std(as_coh)} {get_pvalues(ts_coh,ss_coh)} {get_pvalues(ts_coh,as_coh)} {get_pvalues(as_coh,ss_coh)}\")\n",
    "print(f\"UEVALCON {np.mean(ts_con)} {np.std(ts_con)} {np.mean(ss_con)} {np.std(ss_con)} {np.mean(as_con)} {np.std(as_con)} {get_pvalues(ts_con,ss_con)} {get_pvalues(ts_con,as_con)} {get_pvalues(as_con,ss_con)}\")\n",
    "print(f\"UEVALFLU {np.mean(ts_flu)} {np.std(ts_flu)} {np.mean(ss_flu)} {np.std(ss_flu)} {np.mean(as_flu)} {np.std(as_flu)} {get_pvalues(ts_flu,ss_flu)} {get_pvalues(ts_flu,as_flu)} {get_pvalues(as_flu,ss_flu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ec097",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'summarization'\n",
    "\n",
    "evaluator = get_evaluator(task)\n",
    "\n",
    "\n",
    "def compute_unieval_scores(hyp_list,ref_list,src_list):\n",
    "    data = convert_to_json(src_list=src_list, ref_list=ref_list,output_list=hyp_list)\n",
    "    eval_scores = evaluator.evaluate(data, dims=['relevance'], \n",
    "                                 overall=False, print_result=False)\n",
    "    return [x[\"relevance\"] for x in eval_scores]\n",
    "\n",
    "\n",
    "\n",
    "ts1_rel = compute_unieval_scores(text_summary1,text_summary2,src)\n",
    "ts2_rel = compute_unieval_scores(text_summary2,text_summary1,src)\n",
    "ss1_rel = compute_unieval_scores(audio_summary1,audio_summary2,src)\n",
    "ss2_rel = compute_unieval_scores(audio_summary2,audio_summary1,src)\n",
    "as1_rel = compute_unieval_scores(asr_summary1,asr_summary2,src)\n",
    "as2_rel = compute_unieval_scores(asr_summary2,asr_summary1,src)\n",
    "\n",
    "ts_rel = ts1_rel + ts2_rel\n",
    "ss_rel = ss1_rel + ss2_rel\n",
    "as_rel = as1_rel + as2_rel\n",
    "\n",
    "print(f\"REL {np.mean(ts_rel)} {np.std(ts_rel)} {np.mean(ss_rel)} {np.std(ss_rel)} {np.mean(as_rel)} {np.std(as_rel)} {get_pvalues(ts_rel,ss_rel)} {get_pvalues(ts_rel,as_rel)} {get_pvalues(as_rel,ss_rel)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c689679",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'summarization'\n",
    "\n",
    "evaluator = get_evaluator(task)\n",
    "\n",
    "\n",
    "def compute_unieval_scores(hyp_list,ref_list,src_list):\n",
    "    data = convert_to_json(src_list=src_list, ref_list=ref_list,output_list=hyp_list)\n",
    "    eval_scores = evaluator.evaluate(data, dims=['relevance'], \n",
    "                                 overall=False, print_result=True)\n",
    "    return [x[\"relevance\"] for x in eval_scores]\n",
    "\n",
    "\n",
    "\n",
    "ts12_rel =  compute_unieval_scores(text_summary1,audio_summary2,src)\n",
    "ts11_rel =  compute_unieval_scores(text_summary1,audio_summary1,src)\n",
    "\n",
    "ts22_rel =  compute_unieval_scores(text_summary2,audio_summary2,src)\n",
    "ts21_rel = compute_unieval_scores(text_summary2,audio_summary1,src)\n",
    "\n",
    "ta12_rel =  compute_unieval_scores(text_summary1,asr_summary2,src)\n",
    "ta11_rel =  compute_unieval_scores(text_summary1,asr_summary1,src)\n",
    "\n",
    "ta22_rel =  compute_unieval_scores(text_summary2,asr_summary2,src)\n",
    "ta21_rel = compute_unieval_scores(text_summary2,asr_summary1,src)\n",
    "\n",
    "\n",
    "st12_rel =  compute_unieval_scores(audio_summary1,text_summary2,src)\n",
    "st11_rel = compute_unieval_scores(audio_summary1,text_summary1,src)\n",
    "\n",
    "st22_rel = compute_unieval_scores(audio_summary2,text_summary2,src)\n",
    "st21_rel = compute_unieval_scores(audio_summary2,text_summary1,src)\n",
    "\n",
    "sa11_rel =  compute_unieval_scores(audio_summary1,asr_summary1,src)\n",
    "sa12_rel =  compute_unieval_scores(audio_summary1,asr_summary2,src)\n",
    "\n",
    "sa21_rel =  compute_unieval_scores(audio_summary2,asr_summary1,src)\n",
    "sa22_rel = compute_unieval_scores(audio_summary2,asr_summary2,src)\n",
    "\n",
    "as12_rel =  compute_unieval_scores(asr_summary1,text_summary2,src)\n",
    "as11_rel =  compute_unieval_scores(asr_summary1,text_summary1,src)\n",
    "\n",
    "as22_rel =  compute_unieval_scores(asr_summary2,text_summary2,src)\n",
    "as21_rel = compute_unieval_scores(asr_summary2,text_summary1,src)\n",
    "\n",
    "at12_rel =  compute_unieval_scores(asr_summary1,audio_summary2,src)\n",
    "at11_rel =  compute_unieval_scores(asr_summary1,audio_summary1,src)\n",
    "\n",
    "at22_rel =  compute_unieval_scores(asr_summary2,audio_summary2,src)\n",
    "at21_rel = compute_unieval_scores(asr_summary2,audio_summary1,src)\n",
    "\n",
    "text_all = ts12_rel + ts11_rel + ts21_rel + ts22_rel + ta12_rel + ta11_rel + ta21_rel + ta22_rel\n",
    "audio_all = st12_rel + st11_rel + st21_rel + st22_rel + sa11_rel + sa12_rel + sa21_rel + sa22_rel\n",
    "asr_all = as12_rel + as11_rel + as21_rel + as22_rel + at12_rel + at11_rel + at21_rel + at22_rel\n",
    "\n",
    "\n",
    "print(f\"RELPAIR {np.mean(text_all)} {np.std(text_all)} {np.mean(audio_all)} {np.std(audio_all)} {np.mean(asr_all)} {np.std(asr_all)} {get_pvalues(text_all,audio_all)} {get_pvalues(text_all,asr_all)} {get_pvalues(asr_all,audio_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcacbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'summarization'\n",
    "\n",
    "evaluator = get_evaluator(task)\n",
    "\n",
    "\n",
    "def compute_unieval_scores(hyp_list,ref_list,src_list):\n",
    "    data = convert_to_json(src_list=src_list, ref_list=ref_list,output_list=hyp_list)\n",
    "    eval_scores = evaluator.evaluate(data, dims=['consistency'], \n",
    "                                 overall=False, print_result=True)\n",
    "    return [x[\"consistency\"] for x in eval_scores]\n",
    "\n",
    "\n",
    "\n",
    "ts12_rel =  compute_unieval_scores(text_summary1,audio_summary2,src)\n",
    "ts11_rel =  compute_unieval_scores(text_summary1,audio_summary1,src)\n",
    "\n",
    "ts22_rel =  compute_unieval_scores(text_summary2,audio_summary2,src)\n",
    "ts21_rel = compute_unieval_scores(text_summary2,audio_summary1,src)\n",
    "\n",
    "ta12_rel =  compute_unieval_scores(text_summary1,asr_summary2,src)\n",
    "ta11_rel =  compute_unieval_scores(text_summary1,asr_summary1,src)\n",
    "\n",
    "ta22_rel =  compute_unieval_scores(text_summary2,asr_summary2,src)\n",
    "ta21_rel = compute_unieval_scores(text_summary2,asr_summary1,src)\n",
    "\n",
    "\n",
    "st12_rel =  compute_unieval_scores(audio_summary1,text_summary2,src)\n",
    "st11_rel = compute_unieval_scores(audio_summary1,text_summary1,src)\n",
    "\n",
    "st22_rel = compute_unieval_scores(audio_summary2,text_summary2,src)\n",
    "st21_rel = compute_unieval_scores(audio_summary2,text_summary1,src)\n",
    "\n",
    "sa11_rel =  compute_unieval_scores(audio_summary1,asr_summary1,src)\n",
    "sa12_rel =  compute_unieval_scores(audio_summary1,asr_summary2,src)\n",
    "\n",
    "sa21_rel =  compute_unieval_scores(audio_summary2,asr_summary1,src)\n",
    "sa22_rel = compute_unieval_scores(audio_summary2,asr_summary2,src)\n",
    "\n",
    "as12_rel =  compute_unieval_scores(asr_summary1,text_summary2,src)\n",
    "as11_rel =  compute_unieval_scores(asr_summary1,text_summary1,src)\n",
    "\n",
    "as22_rel =  compute_unieval_scores(asr_summary2,text_summary2,src)\n",
    "as21_rel = compute_unieval_scores(asr_summary2,text_summary1,src)\n",
    "\n",
    "at12_rel =  compute_unieval_scores(asr_summary1,audio_summary2,src)\n",
    "at11_rel =  compute_unieval_scores(asr_summary1,audio_summary1,src)\n",
    "\n",
    "at22_rel =  compute_unieval_scores(asr_summary2,audio_summary2,src)\n",
    "at21_rel = compute_unieval_scores(asr_summary2,audio_summary1,src)\n",
    "\n",
    "text_all = ts12_rel + ts11_rel + ts21_rel + ts22_rel + ta12_rel + ta11_rel + ta21_rel + ta22_rel\n",
    "audio_all = st12_rel + st11_rel + st21_rel + st22_rel + sa11_rel + sa12_rel + sa21_rel + sa22_rel\n",
    "asr_all = as12_rel + as11_rel + as21_rel + as22_rel + at12_rel + at11_rel + at21_rel + at22_rel\n",
    "\n",
    "\n",
    "print(f\"CONPAIR {np.mean(text_all)} {np.std(text_all)} {np.mean(audio_all)} {np.std(audio_all)} {np.mean(asr_all)} {np.std(asr_all)} {get_pvalues(text_all,audio_all)} {get_pvalues(text_all,asr_all)} {get_pvalues(asr_all,audio_all)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da63fcd",
   "metadata": {},
   "source": [
    "# BARTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822b40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd BARTScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf771ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bart_score import BARTScorer\n",
    "bart_scorer = BARTScorer(device='cuda:0', checkpoint='facebook/bart-large-cnn')\n",
    "\n",
    "text1_scores = bart_scorer.score(text_summary1,src,batch_size=4)\n",
    "text2_scores = bart_scorer.score(text_summary2,src,batch_size=4)\n",
    "audio1_scores = bart_scorer.score(audio_summary1,src,batch_size=4)\n",
    "audio2_scores = bart_scorer.score(audio_summary2,src,batch_size=4)\n",
    "asr1_scores = bart_scorer.score(asr_summary1,src,batch_size=4)\n",
    "asr2_scores = bart_scorer.score(asr_summary2,src,batch_size=4)\n",
    "\n",
    "text_score = text1_scores+text2_scores\n",
    "audio_score = audio1_scores+audio2_scores\n",
    "asr_score = asr1_scores+asr2_scores\n",
    "\n",
    "\n",
    "print(f\"BARTSCORE {np.mean(text_score)} {np.std(text_score)} {np.mean(audio_score)} {np.std(audio_score)} {np.mean(asr_score)} {np.std(asr_score)} {get_pvalues(text_score,audio_score)} {get_pvalues(text_score,asr_score)} {get_pvalues(asr_score,audio_score)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af104350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interannotator_bart_score(hyp,ref):\n",
    "    results1 = bart_scorer.score(hyp,ref,batch_size=4)\n",
    "    results2 = bart_scorer.score(ref,hyp,batch_size=4)\n",
    "    return np.mean(results1+results2),np.std(results1+results2),results1+results2\n",
    "\n",
    "text_interannotator_bartscore,text_std,text_sc = get_interannotator_bart_score(text_summary1,text_summary2)\n",
    "audio_interannotator_bartscore,audio_std,audio_sc = get_interannotator_bart_score(audio_summary1,audio_summary2)\n",
    "asr_interannotator_bartscore,asr_std,asr_sc = get_interannotator_bart_score(asr_summary1,asr_summary2)\n",
    "\n",
    "print(f\"INTERBARTSCORE {text_interannotator_bartscore} {text_std} {audio_interannotator_bartscore} {audio_std} {asr_interannotator_bartscore} {asr_std} {get_pvalues(text_sc,audio_sc)} {get_pvalues(text_sc,asr_sc)} {get_pvalues(asr_sc,audio_sc)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1_ref_speech1hyp = bart_scorer.score(audio_summary1,text_summary1,batch_size=4)\n",
    "text1_ref_speech2hyp = bart_scorer.score(audio_summary2,text_summary1,batch_size=4)\n",
    "\n",
    "text2_ref_speech1hyp = bart_scorer.score(audio_summary1,text_summary2,batch_size=4)\n",
    "text2_ref_speech2hyp = bart_scorer.score(audio_summary2,text_summary2,batch_size=4)\n",
    "\n",
    "text1_ref_asr1hyp = bart_scorer.score(asr_summary1,text_summary1,batch_size=4)\n",
    "text1_ref_asr2hyp = bart_scorer.score(asr_summary2,text_summary1,batch_size=4)\n",
    "\n",
    "text2_ref_asr1hyp = bart_scorer.score(asr_summary1,text_summary2,batch_size=4)\n",
    "text2_ref_asr2hyp = bart_scorer.score(asr_summary2,text_summary2,batch_size=4)\n",
    "\n",
    "speech1_ref_text1hyp = bart_scorer.score(text_summary1,audio_summary1,batch_size=4)\n",
    "speech1_ref_text2hyp = bart_scorer.score(text_summary2,audio_summary1,batch_size=4)\n",
    "\n",
    "speech2_ref_text1hyp = bart_scorer.score(text_summary1,audio_summary2,batch_size=4)\n",
    "speech2_ref_text2hyp = bart_scorer.score(text_summary2,audio_summary2,batch_size=4)\n",
    "\n",
    "speech1_ref_asr1hyp = bart_scorer.score(asr_summary1,audio_summary1,batch_size=4)\n",
    "speech1_ref_asr2hyp = bart_scorer.score(asr_summary2,audio_summary1,batch_size=4)\n",
    "\n",
    "speech2_ref_asr1hyp = bart_scorer.score(asr_summary1,audio_summary2,batch_size=4)\n",
    "speech2_ref_asr2hyp = bart_scorer.score(asr_summary2,audio_summary2,batch_size=4)\n",
    "\n",
    "asr1_ref_text1hyp = bart_scorer.score(text_summary1,asr_summary1,batch_size=4)\n",
    "asr1_ref_text2hyp = bart_scorer.score(text_summary2,asr_summary1,batch_size=4)\n",
    "\n",
    "asr2_ref_text1hyp = bart_scorer.score(text_summary1,asr_summary2,batch_size=4)\n",
    "asr2_ref_text2hyp = bart_scorer.score(text_summary2,asr_summary2,batch_size=4)\n",
    "\n",
    "asr1_ref_speech1hyp = bart_scorer.score(audio_summary1,asr_summary1,batch_size=4)\n",
    "asr1_ref_speech2hyp = bart_scorer.score(audio_summary2,asr_summary1,batch_size=4)\n",
    "\n",
    "asr2_ref_speech1hyp = bart_scorer.score(audio_summary1,asr_summary2,batch_size=4)\n",
    "asr2_ref_speech2hyp = bart_scorer.score(audio_summary2,asr_summary2,batch_size=4)\n",
    "\n",
    "\n",
    "\n",
    "text_all = text1_ref_speech1hyp+text1_ref_speech2hyp+text2_ref_speech1hyp+text2_ref_speech2hyp + text1_ref_asr1hyp+text1_ref_asr2hyp+text2_ref_asr1hyp+text2_ref_asr2hyp\n",
    "speech_all = speech1_ref_text1hyp+speech1_ref_text2hyp+speech2_ref_text1hyp+speech2_ref_text2hyp + speech1_ref_asr1hyp+speech1_ref_asr2hyp+speech2_ref_asr1hyp+speech2_ref_asr2hyp\n",
    "asr_all = asr1_ref_text1hyp+asr1_ref_text2hyp+asr2_ref_text1hyp+asr2_ref_text2hyp + asr1_ref_speech1hyp+asr1_ref_speech2hyp+asr2_ref_speech1hyp+asr2_ref_speech2hyp\n",
    "\n",
    "print(f\"PAIRBARTSCORE {np.mean(text_all)} {np.std(text_all)} {np.mean(speech_all)} {np.std(speech_all)} {np.mean(asr_all)} {np.std(asr_all)} {get_pvalues(text_all,speech_all)} {get_pvalues(text_all,asr_all)} {get_pvalues(asr_all,speech_all)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e5aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "\n",
    "def get_bertscore_retrieval(hyp_summary,refs):\n",
    "    hyp = [hyp_summary]*len(refs)\n",
    "    results = bertscore.compute(predictions=hyp,references=refs,lang=\"en\",device=\"cuda:0\")\n",
    "    return results[\"f1\"]\n",
    "\n",
    "    \n",
    "def get_retrieval_acc_entropy(hyp_summary,i):\n",
    "    \n",
    "    scores = np.array(get_bertscore_retrieval(hyp_summary,src))\n",
    "    index = np.argmax(scores,axis=0)\n",
    "    retrieval_acc = 1 if index == i else 0\n",
    "    normalized_scores = scores/scores.sum()\n",
    "    entropy = scipy.stats.entropy(normalized_scores)\n",
    "    return retrieval_acc,entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f5eb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_summary1_retr = output_df.apply(lambda x: get_retrieval_acc_entropy(x[\"Text_Summary1\"],x[\"index\"]),axis=1)\n",
    "text_summary2_retr = output_df.apply(lambda x: get_retrieval_acc_entropy(x[\"Text_Summary2\"],x[\"index\"]),axis=1)\n",
    "\n",
    "text_retr_acc = 0.5 * (np.mean([x[0] for x in text_summary1_retr]) + np.mean([x[0] for x in text_summary2_retr]))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Text Source Retrieval Acc is {text_retr_acc}\")\n",
    "\n",
    "text_retr_ent = 0.5 * (np.mean([x[1] for x in text_summary1_retr]) + np.mean([x[1] for x in text_summary2_retr]))\n",
    "print(f\"Text Source Ent is {text_retr_ent}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "audio_summary1_retr = output_df.apply(lambda x: get_retrieval_acc_entropy(x[\"Audio_Summary1\"],x[\"index\"]),axis=1)\n",
    "audio_summary2_retr = output_df.apply(lambda x: get_retrieval_acc_entropy(x[\"Audio_Summary2\"],x[\"index\"]),axis=1)\n",
    "audio_retr_acc = 0.5 * (np.mean([x[0] for x in audio_summary1_retr]) + np.mean([x[0] for x in audio_summary2_retr]))\n",
    "print(f\"Audio Source Retrieval Acc is {audio_retr_acc}\")\n",
    "\n",
    "audio_retr_ent = 0.5 * (np.mean([x[1] for x in audio_summary1_retr]) + np.mean([x[1] for x in audio_summary2_retr]))\n",
    "print(f\"Audio Source Ent Acc is {audio_retr_ent}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "asr_summary1_retr = output_df.apply(lambda x: get_retrieval_acc_entropy(x[\"Whisper_Transcript_Summary1\"],x[\"index\"]),axis=1)\n",
    "asr_summary2_retr = output_df.apply(lambda x: get_retrieval_acc_entropy(x[\"Whisper_Transcript_Summary2\"],x[\"index\"]),axis=1)\n",
    "asr_retr_acc = 0.5 * (np.mean([x[0] for x in asr_summary1_retr]) + np.mean([x[0] for x in asr_summary2_retr]))\n",
    "print(f\"ASR Source Retrieval Acc is {asr_retr_acc}\")\n",
    "\n",
    "asr_retr_ent = 0.5 * (np.mean([x[1] for x in asr_summary1_retr]) + np.mean([x[1] for x in asr_summary2_retr]))\n",
    "print(f\"ASR Source Ent Acc is {asr_retr_ent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f974ee10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
